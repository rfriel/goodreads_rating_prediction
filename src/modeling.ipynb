{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from scrape_GR_tools import *\n",
    "from scrape_explore import *\n",
    "from friend_groups import *\n",
    "from modeling import *\n",
    "#put this in scrape_GR_tools\n",
    "import pandas as pd\n",
    "\n",
    "import graphlab as gl\n",
    "gl.set_runtime_config('GRAPHLAB_DEFAULT_NUM_PYLAMBDA_WORKERS', 36)\n",
    "\n",
    "import networkx as nx\n",
    "import nxpd as nxpd\n",
    "from IPython.display import display, Image\n",
    "import community\n",
    "\n",
    "from datetime import date, datetime\n",
    "grDateFormat = '%b %d, %Y'\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from itertools import product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING UP DATA FOR PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mongoClientName = \"mongodb://XXX\" # replace XXX with the location of your mongo client\n",
    "# here I used one of my Amazon EC2 instances and its associated storage as a central location for MongoDB\n",
    "client = MongoClient(mongoClientName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking database 'goodreads_explore_from_book_heLa'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_rebelOfTheSands'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_aCourtOfMistAndFury'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_evicted'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_beautifulDisaster'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_childhoodsEnd'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_theMirrorKing'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Checking database 'goodreads_explore_from_book_outlander'\n",
      "Comms collection malformed or empty: expected 1 record, found 0 records\n",
      "\n",
      "Finished collecting comms.  We have 0 comms in total.  Pruning...\n",
      "\n",
      "Began with 0 comms, now have 0 after pruning.\n"
     ]
    }
   ],
   "source": [
    "added_later = {'huckFinn', 'eatPrayLove', 'valis', 'mistborn', 'catsCradle',\n",
    "              'secret', 'dorianGray', 'rothfussName'}\n",
    "\n",
    "allComms = collectAllComms(client, db_exclude={}, removeOutliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMAySpMb/AWk03AZXi2j+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffc3fa43f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(c) for c in allComms]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbFull = client['goodreads_full']\n",
    "\n",
    "ratingsFull = dbFull['ratings']\n",
    "friendsFull = dbFull['friends']\n",
    "booksFull = dbFull['books']\n",
    "\n",
    "#updateCommsOfRaters2(booksFull, allComms)\n",
    "#updateCommsOfRaters(ratingsFull, booksFull, allComms)\n",
    "booksToRaterComms = getCommsOfRaters(ratingsFull, allComms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glRatings = makeRecommenderInputs(ratingsFull, booksFull, allComms, booksToRaterComms, 20, 20, False)\n",
    "#outlierDict, glRatingsNoOutliers = removeGlOutliers(glRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#glRatings = glRatingsNoOutliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSplitRmses = []\n",
    "trainSplitRmsesFake = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glRatingsTrain, glRatingsTest = gl.recommender.util.random_split_by_user(glRatings, \n",
    "                                                    user_id=\"userID\", \n",
    "                                                    item_id=\"bookID\",\n",
    "                                                    max_num_users=1000,\n",
    "                                                    item_test_proportion=0.2)\n",
    "'''\n",
    "\n",
    "glRatingsTrain, glRatingsTest = makeRecommenderInputs(ratingsFull, booksFull, allComms, booksToRaterComms, 20, 20,\\\n",
    "                                                     True, datetime.strptime('Apr 17, 2013', grDateFormat))\n",
    "\n",
    "glRatingsTrain = glRatingsTrain[glRatingsTrain['comm'].apply(lambda x: outlierDict[x])]\n",
    "glRatingsTest = glRatingsTest[glRatingsTest['comm'].apply(lambda x: outlierDict[x])]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDA comparing movielens to GR\n",
    "# loading data\n",
    "\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df_ml = pd.read_csv('ml-100k/u.data', sep='\\t', names=header)\n",
    "df_ml = df_ml.rename(columns={'user_id':'userID','item_id':'bookID'})\n",
    "\n",
    "df_gr = glRatings.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA comparing movielens to GR\n",
    "\n",
    "df_ml_users = df_ml.groupby(['userID'])['rating'].count()\n",
    "print 'movielens: ratings per user stats\\n'\n",
    "print df_ml_users.describe()\n",
    "\n",
    "print '\\n\\ngoodreads: ratings per user stats\\n'\n",
    "df_gr_users = df_gr.groupby(['userID'])['rating'].count()\n",
    "print df_gr_users.describe()\n",
    "\n",
    "df_ml_items = df_ml.groupby(['bookID'])['rating'].count()\n",
    "print '\\n\\nmovielens: ratings per item stats\\n'\n",
    "print df_ml_items.describe()\n",
    "\n",
    "print '\\n\\ngoodreads: ratings per item stats\\n'\n",
    "df_gr_items = df_gr.groupby(['bookID'])['rating'].count()\n",
    "print df_gr_items.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histStuff= plt.hist(df_ml_users,alpha=0.25,normed=True,log=True,bins=np.linspace(0,300,30),label='ml');\n",
    "plt.hist(df_gr_users,alpha=0.25,bins=histStuff[1],normed=True,log=True,color='r',label='gr');\n",
    "plt.legend(title='PDF: ratings per user');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histStuff= plt.hist(df_ml_items,alpha=0.25,normed=True,log=True,bins=np.linspace(0,300,30),label='ml');\n",
    "plt.hist(df_gr_items,alpha=0.25,bins=histStuff[1],normed=True,log=True,color='r',label='gr');\n",
    "plt.legend(title='PDF: ratings per items');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_ml_users,df_ml_users.rank()/len(df_ml_users.rank()),'o',label='ml');\n",
    "plt.plot(df_gr_users,df_gr_users.rank()/len(df_gr_users.rank()),'o',label='gr');\n",
    "plt.axis([0,300,0,1])\n",
    "plt.legend(title='CDF: ratings per user');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_ml_items,df_ml_items.rank()/len(df_ml_items.rank()),'o',label='ml');\n",
    "plt.plot(df_gr_items,df_gr_items.rank()/len(df_gr_items.rank()),'o',label='gr');\n",
    "plt.axis([0,100,0,1])\n",
    "plt.legend(title='CDF: ratings per item');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on movielens\n",
    "\n",
    "# header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# df_ml = pd.read_csv('ml-100k/u.data', sep='\\t', names=header)\n",
    "# df_ml = df_ml.rename(columns={'user_id':'userID','item_id':'bookID'})\n",
    "\n",
    "# glRatings = gl.SFrame(df_ml)\n",
    "\n",
    "# glRatingsTrain, glRatingsTest = gl.recommender.util.random_split_by_user(glRatings, \n",
    "#                                                     user_id=\"userID\", \n",
    "#                                                     item_id=\"bookID\",\n",
    "#                                                     max_num_users=None,\n",
    "#                                                     item_test_proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing intercept and user/book means\n",
    "\n",
    "# intercept = glRatingsTrain['rating'].mean()\n",
    "\n",
    "# glRatingsTrain['rating'] = glRatingsTrain['rating'] - intercept\n",
    "\n",
    "# userMeans = glRatingsTrain.groupby(['userID'],{'userMeans': gl.aggregate.AVG('rating')})\n",
    "# bookMeans = glRatingsTrain.groupby(['bookID'],{'bookMeans': gl.aggregate.AVG('rating')})\n",
    "\n",
    "# userMeansDict = defaultdict(float,{u['userID']:u['userMeans'] for u in userMeans})\n",
    "# bookMeansDict = defaultdict(float,{b['bookID']:b['bookMeans'] for b in bookMeans})\n",
    "\n",
    "# userShiftsTrain = glRatingsTrain.apply(lambda x: userMeansDict[x['userID']])\n",
    "# bookShiftsTrain = glRatingsTrain.apply(lambda x: bookMeansDict[x['bookID']])\n",
    "\n",
    "# glRatingsTrain['rating'] = glRatingsTrain['rating'] - userShiftsTrain - bookShiftsTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing intercept and user/book means\n",
    "\n",
    "# removing train means from test here is not data leakage -- it's a hack to mimic a recommender that memorizes\n",
    "# the means from the training data and uses them to predict\n",
    "# (to get around the fact that graphlab's recommenders can't use ALS optimization with linear/intercept terms)\n",
    "\n",
    "# glRatingsTest['rating'] = glRatingsTest['rating'] - intercept\n",
    "\n",
    "# userShiftsTest = glRatingsTest.apply(lambda x: userMeansDict[x['userID']])\n",
    "# bookShiftsTest = glRatingsTest.apply(lambda x: bookMeansDict[x['bookID']])\n",
    "\n",
    "# glRatingsTest['rating'] = glRatingsTest['rating'] - userShiftsTest - bookShiftsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print glRatingsTrain.shape[0]\n",
    "print glRatingsTest.shape[0]\n",
    "print float(glRatingsTest.shape[0]) / (glRatingsTest.shape[0] + glRatingsTrain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsByUser = glRatings.groupby(['userID'], {'numRatings': gl.aggregate.COUNT('rating')})['numRatings']\n",
    "numRatingsByUser = pd.Series(numRatingsByUser)\n",
    "numRatingsByUser.describe()\n",
    "#(numRatingsByUser >= 20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsByBook = glRatings.groupby(['bookID'], {'numRatings': gl.aggregate.COUNT('rating')})['numRatings']\n",
    "numRatingsByBook = pd.Series(numRatingsByBook)\n",
    "(numRatingsByBook >= 20).mean()\n",
    "numRatingsByBook.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRADITIONAL RECOMMENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure we train the recommender without community information\n",
    "\n",
    "glRatingsTrainWithComm = glRatingsTrain.copy()\n",
    "glRatingsTestWithComm = glRatingsTest.copy()\n",
    "\n",
    "if 'comm' in glRatingsTrain.column_names():\n",
    "    glRatingsTrain.remove_column('comm');\n",
    "if 'comm' in glRatingsTest.column_names():\n",
    "    glRatingsTest.remove_column('comm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degreesOfFreedomStats(glRatingsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TRANSFORMING TO UNIFORM DISTRIBUTION\n",
    "rating_cats = range(1,6)\n",
    "rating_counts = np.array([sum(np.array(glRatingsTrain['rating']) == rating) for rating in rating_cats])\n",
    "transformed_ratings = 1 + np.cumsum(4*rating_counts/float(rating_counts.sum()))\n",
    "transformed_rating_dict = dict(zip(rating_cats,transformed_ratings))\n",
    "transformed_rating_dict_inv = {v:k for (k,v) in transformed_rating_dict.items()}\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.hist(glRatingsTest['rating'],normed=True,alpha=1,bins=[0.5,2.5,4.5,6.5]);\n",
    "plt.subplot(122)\n",
    "plt.hist(glRatingsTest['rating'].apply(lambda x: transformed_rating_dict[x]),normed=True,alpha=0.5,color='r',\\\n",
    "        bins=[0.5,2.5,4.5,6.5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the two lines below scale to uniform dist\n",
    "glRatingsTrain['rating'] = glRatingsTrain['rating'].apply(lambda x: transformed_rating_dict[x])\n",
    "glRatingsTest['rating'] = glRatingsTest['rating'].apply(lambda x: transformed_rating_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path_train='gl_gr_train'\n",
    "file_path_test='gl_gr_test'\n",
    "file_path_all='gl_gr_all'\n",
    "\n",
    "glRatingsTrain['userID','bookID','rating'].export_csv(file_path_train,header=True,delimiter='\\t')\n",
    "glRatingsTest['userID','bookID','rating'].export_csv(file_path_test,header=True,delimiter='\\t')\n",
    "glRatings['userID','bookID','rating'].export_csv(file_path_all,header=True,delimiter='\\t')\n",
    "#glRatingsTrain = gl.SFrame.read_csv(file_path_train,header=True,delimiter='\\t')\n",
    "#glRatingsTest = gl.SFrame.read_csv(file_path_test,header=True,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, KNNBaseline\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import evaluate, GridSearch, print_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', sep='\\t', skip_lines=1)\n",
    "surpriseTrain = Dataset.load_from_file(file_path_train, reader=reader).build_full_trainset()\n",
    "surpriseTest = Dataset.load_from_file(file_path_test, reader=reader).build_full_trainset()\n",
    "\n",
    "train_folds = Dataset.load_from_file(file_path_all, reader=reader)\n",
    "train_folds.split(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kNNBaseline_GridSearch = GridSearch(KNNBaseline, {'k':range(50,130,10)}, measures=['rmse','fcp'])\n",
    "kNNBaseline_GridSearch.evaluate(train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.plot([kNNBaseline_GridSearch.cv_results['params'][i]['k'] for i in range(8)],\n",
    "        [kNNBaseline_GridSearch.cv_results['scores'][i]['RMSE'] for i in range(8)])\n",
    "plt.subplot(122)\n",
    "plt.plot([kNNBaseline_GridSearch.cv_results['params'][i]['k'] for i in range(8)],\n",
    "        [kNNBaseline_GridSearch.cv_results['scores'][i]['FCP'] for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_KNNBaseline = KNNBaseline(k=kNNBaseline_GridSearch.best_params['rmse']['k'])\n",
    "\n",
    "gr_KNNBaseline.train(surpriseTrain)\n",
    "\n",
    "\n",
    "preds=[gr_KNNBaseline.predict(str(row['userID']),str(row['bookID']),row['rating']) for row in glRatingsTest]\n",
    "preds_est = np.array([preds[i].est for i in range(len(preds))])\n",
    "preds_true = np.array([preds[i].r_ui for i in range(len(preds))])\n",
    "\n",
    "errs = preds_true - preds_est\n",
    "rmse = np.sqrt((errs**2).mean())\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = {'n_factors': [160], 'reg_all': [2e-1,1e-1],\n",
    "                                  'reg_bu': [1e-10], 'reg_bi': [1e-10],\n",
    "                                  'n_epochs':[60,120,400], 'lr_all': [1e-2,5e-3,1e-3]}\n",
    "dd = [[(k, v) for v in grid[k]] for k in grid]\n",
    "grid_list = [{param[0]: param[1] for param in t} for t in product(*dd) ]\n",
    "\n",
    "grid_rmses = {}\n",
    "for i, params in enumerate(grid_list):\n",
    "    print 'Parameters combination %d of %d' % (i, len(grid_list))\n",
    "    print params\n",
    "    gr_SVD = SVD(**params)\n",
    "    gr_SVD.train(surpriseTrain)\n",
    "\n",
    "    preds=[gr_SVD.predict(str(row['userID']),str(row['bookID']),row['rating']) for row in glRatingsTest]\n",
    "    preds_est = np.array([preds[i].est for i in range(len(preds))])\n",
    "    preds_true = np.array([preds[i].r_ui for i in range(len(preds))])\n",
    "\n",
    "    errs = preds_true - preds_est\n",
    "    rmse = np.sqrt((errs**2).mean())\n",
    "    print rmse\n",
    "    print ''\n",
    "    params_tup = tuple((k, v) for k, v in params.iteritems())\n",
    "    grid_rmses[params_tup] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmses_list = grid_rmses.items()\n",
    "sort_inds = np.argsort([v for k, v in rmses_list])\n",
    "# for i in range(len(sort_inds)):\n",
    "#     print {k:v for k, v in rmses_list[sort_inds[i]][0]}\n",
    "#     print rmses_list[sort_inds[i]][1]\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gl_grid = {rmses_list[sort_inds[0]][0][i][0]: \\\n",
    "           [rmses_list[ind][0][i][1] for ind in sort_inds] for i in range(len(grid))}\n",
    "gl_grid['rmse'] = [rmses_list[ind][1] for ind in sort_inds]\n",
    "gl_output = gl.SFrame(gl_grid)\n",
    "gl_output.print_rows(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = [5, 20, 100, 200, 400, 800, 1600]\n",
    "rmses = []\n",
    "\n",
    "for ep in epochs:\n",
    "    gr_SVD = SVD(lr_all=0.001, n_epochs=ep, n_factors=160, reg_all=0.1, reg_bu=1e-10, reg_bi=1e-10)\n",
    "    \n",
    "    gr_SVD.train(surpriseTrain)\n",
    "\n",
    "    preds=[gr_SVD.predict(str(row['userID']),str(row['bookID']),row['rating']) for row in glRatingsTest]\n",
    "    preds_est = np.array([preds[i].est for i in range(len(preds))])\n",
    "    preds_true = np.array([preds[i].r_ui for i in range(len(preds))])\n",
    "\n",
    "    errs = preds_true - preds_est\n",
    "    rmse = np.sqrt((errs**2).mean())\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {k:v for k,v in rmses_list[sort_inds[0]][0]}\n",
    "gr_SVD = SVD(**best_params)\n",
    "\n",
    "gr_SVD.train(surpriseTrain)\n",
    "\n",
    "preds=[gr_SVD.predict(str(row['userID']),str(row['bookID']),row['rating']) for row in glRatingsTest]\n",
    "preds_est = np.array([preds[i].est for i in range(len(preds))])\n",
    "preds_true = np.array([preds[i].r_ui for i in range(len(preds))])\n",
    "\n",
    "errs = preds_true - preds_est\n",
    "rmse = np.sqrt((errs**2).mean())\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_outer_iid = {surpriseTrain.to_inner_iid(bID): bID for bID in glRatingsTrain['bookID']}\n",
    "\n",
    "\n",
    "factor_norms_sq = np.array([gr_SVD.qi[:,i].dot(gr_SVD.qi[:,i]) for i in range(80)])\n",
    "factor_argsort = np.argsort(factor_norms_sq)\n",
    "for i in range(1):\n",
    "    factor = gr_SVD.qi[:,factor_argsort[i]]\n",
    "    loadings_argsort = np.argsort(factor)\n",
    "    for j in range(5):\n",
    "        print bookTitle(to_outer_iid[loadings_argsort[j]])\n",
    "        print factor[loadings_argsort[j]]\n",
    "    print '\\n'\n",
    "    for j in range(5):\n",
    "        print bookTitle(to_outer_iid[loadings_argsort[::-1][j]])\n",
    "        print factor[loadings_argsort[::-1][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_argsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOCIAL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glCommMeansTrain, glCommBookMeansTrain, commMeansTrain, commBookMeansTrain = \\\n",
    "makeSocialModelInputs(glRatingsTrainWithComm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRatingsByUser = glRatingsTrain.groupby(['userID'], {'numRatings': gl.aggregate.COUNT('rating')})\n",
    "numRatingsByUserDict = defaultdict(int, {r['userID']: r['numRatings'] for r in numRatingsByUser})\n",
    "\n",
    "numRatingsByBook = glRatingsTrain.groupby(['bookID'], {'numRatings': gl.aggregate.COUNT('rating')})\n",
    "numRatingsByBookDict = defaultdict(int, {r['bookID']: r['numRatings'] for r in numRatingsByBook})\n",
    "\n",
    "numTrainRatings_Test = np.array(glRatingsTestWithComm['bookID'].apply(lambda x: numRatingsByBookDict[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjXmax = 100.\n",
    "adjX = numTrainRatings_Test.copy()\n",
    "adjX[adjX>adjXmax] = adjXmax\n",
    "adjWeights = np.tan(2.7*(adjX-(adjXmax/2))/adjXmax)\n",
    "adjWeights = adjWeights / (max(adjWeights)-min(adjWeights))\n",
    "adjWeights = adjWeights - min(adjWeights)\n",
    "\n",
    "#plt.plot(numTrainRatings_Test, adjWeights, 'o')\n",
    "plt.hist(adjWeights)\n",
    "np.median(adjWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "adjWeights=(100. - np.linspace(0,100,100))/100.\n",
    "adjWeights[adjWeights<0]=0\n",
    "adjWeights = adjWeights**(0.5)\n",
    "plt.plot(np.linspace(0,100,100), adjWeights)\n",
    "'''\n",
    "adjX = np.linspace(0,150,100)\n",
    "adjWeights = 0.5*(adjX<30) + 0.5*(adjX < 150)\n",
    "adjWeights2 = np.tan(-2.7*(adjX-75)/150)\n",
    "adjWeights2 = adjWeights2 / (2*max(adjWeights2))\n",
    "adjWeights2 = adjWeights2 - min(adjWeights2)\n",
    "plt.plot(adjX, adjWeights)\n",
    "plt.plot(adjX, adjWeights2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_engine = surprisePredWrapper(gr_SVD)\n",
    "\n",
    "meanWeights = np.linspace(0,0.5,20)\n",
    "\n",
    "#SIMPLE PREDICTION FROM COMM MEANS\n",
    "\n",
    "rmsesSimple = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSimple.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, True, weight)[1])\n",
    "\n",
    "\n",
    "\n",
    "#SIMPLE PREDICTION FROM COMM MEANS (no book means)\n",
    "rmsesSimpleNoBookMeans = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleNoBookMeans.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, False, weight)[1])\n",
    "\n",
    "# trainSplitRmses.append(rmsesSimpleNoBookMeans)\n",
    "\n",
    "#SANITY CHECK\n",
    "\n",
    "# rmsesFake = []\n",
    "\n",
    "# for weight in meanWeights:\n",
    "#     rmsesFake.append(\\\n",
    "#                 mixedPred(glRatingsTestFakeComms, \\\n",
    "#                           fakeCommMeansTrain, fakeCommBookMeansTrain, fakeCommBookMeansTrain, rec_engine, rec_engine, \\\n",
    "#                           numTrainRatings_Test,\\\n",
    "#                           False, False, False, weight)[1])\n",
    "\n",
    "# #FACTORIZING COMM MEANS\n",
    "# rmsesFac = []\n",
    "# for weight in meanWeights:\n",
    "#     rmsesFac.append(\\\n",
    "#                 mixedPred(glRatingsTestWithComm, \\\n",
    "#                           commMeansTrain, commBookMeansTrain, rec_engine_8, rec_engine_8 \\\n",
    "#                           commMeans_rec_engine_baseline, True, False, True, weight)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(meanWeights, rmsesSimple)\n",
    "plt.plot(meanWeights, rmsesSimpleNoBookMeans)\n",
    "\n",
    "optimalWeight = meanWeights[np.argmin(rmsesSimple)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimalPreds = pd.Series(mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, True, optimalWeight)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(glRatingsTest['rating'],normed=True,bins=[0.5,1.5,2.5,3.5,4.5,5.5],alpha=0.5);\n",
    "plt.hist(optimalPreds,normed=True,bins=[0.5,1.5,2.5,3.5,4.5,5.5],alpha=0.5,color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_by_rating = []\n",
    "rating_cats = range(1,6)\n",
    "\n",
    "for rating in rating_cats:\n",
    "    preds_by_rating.append(list(optimalPreds[pd.Series(glRatingsTestWithComm['rating'] == rating).astype(bool)]))\n",
    "\n",
    "plt.violinplot(preds_by_rating, positions=rating_cats,showmeans=True);\n",
    "plt.plot([1,5],[1,5])\n",
    "plt.xlabel('Observed rating');\n",
    "plt.ylabel('Predicted rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_by_rating = []\n",
    "rating_cats = range(1,6)\n",
    "\n",
    "interval_eps = 0.001;\n",
    "transformed_rating_intervals = [(transformed_rating_dict[r] - 0.001, transformed_rating_dict[r] + 0.001)\\\n",
    "                                for r in rating_cats]\n",
    "\n",
    "for rating in rating_cats:\n",
    "    preds_by_rating.append(list(optimalPreds[pd.Series(glRatingsTestWithComm['rating'] == rating).astype(bool)]))\n",
    "\n",
    "plt.violinplot(preds_by_rating, positions=[transformed_rating_dict[r] for r in rating_cats],showmeans=True);\n",
    "plt.plot([min(transformed_rating_dict),max(transformed_rating_dict)],[min(transformed_rating_dict),max(transformed_rating_dict)])\n",
    "plt.xlabel('Observed rating');\n",
    "plt.ylabel('Predicted rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "blueLabel = {0: 'Ensemble Models', 1: None, 2: None}\n",
    "greenLabel = defaultdict(lambda: None,{0: 'Fake Community Models'})\n",
    "\n",
    "for i, rmsesSimpleNoBookMeans in enumerate(trainSplitRmses):\n",
    "    plt.plot(meanWeights, rmsesSimpleNoBookMeans, '-', color='b', label=blueLabel[i], alpha=0.85);\n",
    "#plt.plot(meanWeights, rmsesFake, '-', label='Sanity check');\n",
    "plt.axhline(rmsesSimpleNoBookMeans[0],color='k',linestyle='--', label='Base Model');\n",
    "#plt.axhline(rmsesSimpleNoBookMeans[np.argmin(rmsesSimpleNoBookMeans)],linestyle='--',label='Best Combined Model')\n",
    "\n",
    "for i, curve in enumerate([curve for bootstrapRmsesFake in trainSplitRmsesFake for curve in bootstrapRmsesFake]):\n",
    "    plt.plot(meanWeights, curve, color='g', label=greenLabel[i], alpha=0.25)\n",
    "#plt.axhline(np.mean(bootstrapRmsesFake),linestyle='--',color='g',label='Mean Sanity Check Model')\n",
    "\n",
    "plt.xlabel('Ensemble weight',fontsize=16)\n",
    "plt.ylabel('RMSE',fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='best',fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print meanWeights[np.argmin(rmsesFake)]\n",
    "#print rmsesFake[np.argmin(rmsesFake)]\n",
    "\n",
    "print ''\n",
    "\n",
    "print meanWeights[np.argmin(rmsesSimpleNoBookMeans)]\n",
    "print rmsesSimpleNoBookMeans[np.argmin(rmsesSimpleNoBookMeans)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING COMMUNITY MEANS OF RECOMMENDER PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = [(bookID, userID) for bookID, userID in product(glRatings['bookID'].unique(), glRatings['userID'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "testDict = {}\n",
    "npTest = np.array(test)\n",
    "testDict['bookID'] = npTest[:,0]\n",
    "testDict['userID'] = npTest[:,1]\n",
    "sfTest = gl.SFrame(testDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPreds = rec_engine.predict(sfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfTest.add_column(gl.SArray(allPreds), 'preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commDict = {uID: i for i, comm in enumerate(allComms) for uID in comm}\n",
    "\n",
    "sfTest.add_column(sfTest['userID'].apply(lambda x: commDict[int(x)]), 'comm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfTest[['bookID', 'preds', 'comm']].groupby(['bookID', 'comm'], {'avgPreds': gl.aggregate.AVG('preds')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factorCommBookMeansTrain = {(row['bookID'], row['comm']):  row['preds'] for row in sfTest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanWeights = np.linspace(0,1,20)\n",
    "\n",
    "#SIMPLE PREDICTION FROM COMM MEANS\n",
    "rmsesSimple = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSimple.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, True, weight)[1])\n",
    "\n",
    "#SIMPLE PREDICTION FROM COMM MEANS (no book means)\n",
    "rmsesSimpleNoBookMeans = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleNoBookMeans.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, False, weight)[1])\n",
    "    \n",
    "#FACTORIZING COMM MEANS\n",
    "\n",
    "rmsesFac = []\n",
    "for weight in meanWeights:\n",
    "    rmsesFac.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, factorCommBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          True, False, True, weight)[1])\n",
    "\n",
    "plt.plot(meanWeights, rmsesSimple, '-');\n",
    "plt.plot(meanWeights, rmsesSimpleNoBookMeans, '-');\n",
    "plt.plot(meanWeights, rmsesFac, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print meanWeights[np.argmin(rmsesSimple)]\n",
    "print rmsesSimple[np.argmin(rmsesSimple)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsBase = np.array(rec_engine.predict(glRatingsTestWithComm['bookID', 'userID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACTORIZATION RECOMMENDER FOR RAW (COMMUNITY-BOOK-RATING) DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glCommTrain = glRatingsTrainWithComm.copy()['bookID', 'comm', 'rating']\n",
    "#glCommTest = glRatingsTestWithComm.copy()['bookID', 'comm', 'rating']\n",
    "glCommTrain = glCommBookMeansTrain.copy()\n",
    "\n",
    "glCommTrain['rating'] = glCommTrain['meanBookRatingByComm']\n",
    "glCommTrain.remove_column('meanBookRatingByComm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glCommMeansTest, glCommBookMeansTest, commMeansTest, commBookMeansTest = \\\n",
    "makeSocialModelInputs(glRatingsTestWithComm)\n",
    "\n",
    "glCommTest = glCommBookMeansTest.copy()\n",
    "glCommTest['rating'] = glCommTest['meanBookRatingByComm']\n",
    "glCommTest.remove_column('meanBookRatingByComm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path_train_comm='gl_gr_train_comm'\n",
    "file_path_test_comm='gl_gr_test_comm'\n",
    "\n",
    "glCommTrain['comm','bookID','rating'].export_csv(file_path_train_comm,header=True,delimiter='\\t')\n",
    "glCommTest['comm','bookID','rating'].export_csv(file_path_test_comm,header=True,delimiter='\\t')\n",
    "\n",
    "#glCommTrain = gl.SFrame.read_csv(file_path_train_comm,header=True,delimiter='\\t')\n",
    "#glCommTest = gl.SFrame.read_csv(file_path_test_comm,header=True,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', sep='\\t', skip_lines=1)\n",
    "surpriseTrainComm = Dataset.load_from_file(file_path_train_comm, reader=reader).build_full_trainset()\n",
    "\n",
    "train_folds_comm = Dataset.load_from_file(file_path_train_comm, reader=reader)\n",
    "train_folds_comm.split(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = {'n_factors': [0,80,160], 'reg_all': [1e-1,5e-2,1e-2,5e-3],\n",
    "                                  'reg_bu': [1e-10], 'reg_bi': [1e-10],\n",
    "                                  'n_epochs':[20,60,200], 'lr_all': [2e-2,1e-2,5e-3]}\n",
    "dd = [[(k, v) for v in grid[k]] for k in grid]\n",
    "grid_list = [{param[0]: param[1] for param in t} for t in product(*dd) ]\n",
    "\n",
    "grid_rmses = {}\n",
    "for i, params in enumerate(grid_list):\n",
    "    print 'Parameters combination %d of %d' % (i, len(grid_list))\n",
    "    print params\n",
    "    gr_SVD_comm = SVD(**params)\n",
    "    gr_SVD_comm.train(surpriseTrainComm)\n",
    "\n",
    "    preds=[gr_SVD_comm.predict(row['comm'],str(row['bookID']),row['rating']) for row in glCommTest]\n",
    "    preds_est = np.array([preds[i].est for i in range(len(preds))])\n",
    "    preds_true = np.array([preds[i].r_ui for i in range(len(preds))])\n",
    "\n",
    "    errs = preds_true - preds_est\n",
    "    rmse = np.sqrt((errs**2).mean())\n",
    "    print rmse\n",
    "    print ''\n",
    "    params_tup = tuple((k, v) for k, v in params.iteritems())\n",
    "    grid_rmses[params_tup] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmses_list = grid_rmses.items()\n",
    "sort_inds = np.argsort([v for k, v in rmses_list])\n",
    "# for i in range(len(sort_inds)):\n",
    "#     print {k:v for k, v in rmses_list[sort_inds[i]][0]}\n",
    "#     print rmses_list[sort_inds[i]][1]\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gl_grid = {rmses_list[sort_inds[0]][0][i][0]: \\\n",
    "           [rmses_list[ind][0][i][1] for ind in sort_inds] for i in range(len(grid))}\n",
    "gl_grid['rmse'] = [rmses_list[ind][1] for ind in sort_inds]\n",
    "gl_output = gl.SFrame(gl_grid)\n",
    "gl_output.print_rows(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = {k:v for k,v in rmses_list[sort_inds[0]][0]}\n",
    "gr_SVD_comm = SVD(**best_params)\n",
    "gr_SVD_comm.train(surpriseTrainComm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_engine_comm = surprisePredWrapper(gr_SVD_comm)\n",
    "\n",
    "meanWeights = np.linspace(0,0.5,40)\n",
    "\n",
    "#SIMPLE PREDICTION FROM COMM MEANS\n",
    "\n",
    "rmsesSimple = []\n",
    "for weight in meanWeights:\n",
    "    rmsesSimple.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, True, weight)[1])\n",
    "\n",
    "#SIMPLE PREDICTION FROM COMM MEANS (no book means)\n",
    "rmsesSimpleNoBookMeans = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleNoBookMeans.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, False, weight)[1])\n",
    "                          \n",
    "\n",
    "#FACTORIZATION RECOMMENDER FOR RAW (COMMUNITY-BOOK-RATING) DATA\n",
    "rmsesSocialRec = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSocialRec.append(\\\n",
    "                mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, True, False, weight)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(meanWeights, rmsesSimple, '-', label='simple');\n",
    "plt.plot(meanWeights, rmsesSimpleNoBookMeans, '-', label='simpleNoBookMeans');\n",
    "plt.plot(meanWeights, rmsesSocialRec, '-', label='factor');\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print meanWeights[np.argmin(rmsesSimple)]\n",
    "print rmsesSimple[np.argmin(rmsesSimple)]\n",
    "\n",
    "print ''\n",
    "\n",
    "print meanWeights[np.argmin(rmsesSimpleNoBookMeans)]\n",
    "print rmsesSimpleNoBookMeans[np.argmin(rmsesSimpleNoBookMeans)]\n",
    "\n",
    "print ''\n",
    "\n",
    "\n",
    "print meanWeights[np.argmin(rmsesSocialRec)]\n",
    "print rmsesSocialRec[np.argmin(rmsesSocialRec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestWeightComm = meanWeights[np.argmin(rmsesSimple)]\n",
    "\n",
    "predsComm = mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, True, bestWeightComm)[0]\n",
    "\n",
    "predsBase = mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, False, True, 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signTestFrame = glRatingsTestWithComm[['bookID','userID','comm','rating']].copy()\n",
    "signTestFrame.add_column(gl.SArray(predsComm), 'predsComm')\n",
    "signTestFrame.add_column(gl.SArray(predsBase), 'predsBase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errsBase = np.abs(np.array(signTestFrame['rating'] - signTestFrame['predsBase'])**2)\n",
    "errsBase\n",
    "\n",
    "errsComm = np.abs(np.array(signTestFrame['rating'] - signTestFrame['predsComm'])**2)\n",
    "(errsComm < errsBase).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signTestFrame.add_column(gl.SArray(errsComm), 'errsComm')\n",
    "signTestFrame.add_column(gl.SArray(errsBase), 'errsBase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signTestFrame.groupby(['rating'], {'errsCommAvg': gl.aggregate.AVG('errsComm'),\\\n",
    "                                  'errsBaseAvg': gl.aggregate.AVG('errsBase')}).sort('rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roundedPredsBase = np.round(predsBase)\n",
    "roundedPredsComm = np.round(predsComm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(roundedPredsBase == signTestFrame['rating']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(roundedPredsComm == signTestFrame['rating']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_by_rating = []\n",
    "rating_cats = range(1,6)\n",
    "\n",
    "for rating in rating_cats:\n",
    "    preds_by_rating.append(list(predsComm[np.array(glRatingsTest['rating']) == rating]\\\n",
    "                          -predsBase[np.array(glRatingsTest['rating']) == rating]))\n",
    "\n",
    "plt.violinplot(preds_by_rating, positions=rating_cats);\n",
    "plt.xlabel('Observed rating');\n",
    "plt.ylabel('Predicted rating');\n",
    "#for rating in rating_cats:\n",
    "#    plt.axhline(rating,linestyle='--',linewidth=1,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, category in enumerate(preds_by_rating):\n",
    "    print (i+1, np.median(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(glRatingsTrain['rating'])\n",
    "(glRatingsTrain['rating']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_dict = rec_engine.get('coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict['userID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = set(glRatings['bookID'].unique())\n",
    "numCommsByBook = {k: len(v) for k, v in booksToRaterComms.items() if str(k) in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, v) for k, v in numCommsByBook.items() if v == 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bID in [k for k, v in numCommsByBook.items() if v  == 50]:\n",
    "    print bID\n",
    "    print bookTitle(bID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBID = 2429135\n",
    "\n",
    "commIndices = []\n",
    "allCommBookRatings = []\n",
    "numRaters = []\n",
    "meanRatings = []\n",
    "earliestTimes = []\n",
    "\n",
    "uIDsInGL = set(glRatings['userID'].unique())\n",
    "\n",
    "for commIndex in booksToRaterComms[testBID]:\n",
    "    commRatings = ratingsFull.find({'userID': {'$in': list(set(allComms[commIndex]) & uIDsInGL)}})\n",
    "    commBookRatings = [(r['ratings'][str(testBID)][0], \\\n",
    "                        datetime.strptime(r['ratings'][str(testBID)][2], grDateFormat), \\\n",
    "                        r['userID'])\\\n",
    "                       for r in commRatings if str(testBID) in r['ratings'].keys()]\n",
    "    allCommBookRatings.append(commBookRatings)\n",
    "    \n",
    "    commIndices.append(commIndex)\n",
    "    numRaters.append(len(commBookRatings))\n",
    "    meanRatings.append(np.mean(np.array(commBookRatings)[:,0]))\n",
    "    earliestTimes.append(min(r[1] for r in commBookRatings))\n",
    "\n",
    "timeOrder = np.argsort(earliestTimes)\n",
    "\n",
    "numRatersCumSum = 0\n",
    "for i in timeOrder:\n",
    "    numRatersCumSum += numRaters[i]\n",
    "    if numRaters[i] > 3:\n",
    "        print 'Community %d' % commIndices[i]\n",
    "        print '%d raters' % numRaters[i]\n",
    "        print '%.1f mean rating' % meanRatings[i]\n",
    "        print 'Earliest rating on %s' % datetime.strftime(earliestTimes[i], grDateFormat)\n",
    "        print '\\nTotal raters thus far: %d\\n' % numRatersCumSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantGLratings = glRatings[glRatings.apply(lambda x: x['comm'] == 48 and x['bookID'] == str(testBID))]\n",
    "relevantGLratings.print_rows(num_rows=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantGLratings = signTestFrame[signTestFrame.apply(lambda x: x['comm'] == 48 and x['bookID'] == str(testBID))]\n",
    "relevantGLratings.add_column(gl.SArray(\\\n",
    "                             np.abs(np.array(relevantGLratings['rating'] - relevantGLratings['predsBase']))), \\\n",
    "                             'errsBase')\n",
    "relevantGLratings.add_column(gl.SArray(\\\n",
    "                             np.abs(np.array(relevantGLratings['rating'] - relevantGLratings['predsComm']))), \\\n",
    "                             'errsComm')\n",
    "\n",
    "#relevantGLratings.print_rows(num_rows=42, num_columns=8)\n",
    "print relevantGLratings['errsBase'].mean()\n",
    "print relevantGLratings['errsComm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsByUser = glRatingsTrain.groupby(['userID'], {'numRatings': gl.aggregate.COUNT('rating')})\n",
    "plt.hist(numRatingsByUser['numRatings']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdRatingsTrain = glRatingsTrainWithComm.to_dataframe()\n",
    "pdRatingsTest = glRatingsTestWithComm.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRatingsByUser = glRatingsTrain.groupby(['userID'], {'numRatings': gl.aggregate.COUNT('rating')})\n",
    "numRatingsByUserDict = defaultdict(int, {r['userID']: r['numRatings'] for r in numRatingsByUser})\n",
    "\n",
    "numRatingsByBook = glRatingsTrain.groupby(['bookID'], {'numRatings': gl.aggregate.COUNT('rating')})\n",
    "numRatingsByBookDict = defaultdict(int, {r['bookID']: r['numRatings'] for r in numRatingsByBook})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdRatingsTest['numRatingsByUser'] = pdRatingsTest['userID'].apply(lambda x: numRatingsByUserDict[x])\n",
    "pdRatingsTest['numRatingsByBook'] = pdRatingsTest['bookID'].apply(lambda x: numRatingsByBookDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdRatingsTest['numRatingsByUser'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdRatingsTest['numRatingsByBook'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsCutoffHigh = 100000\n",
    "numRatingsCutoffLow = 50\n",
    "pdManyRatings = pdRatingsTest[(pdRatingsTest['numRatingsByBook'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByBook'] < numRatingsCutoffHigh)]\n",
    "print ((pdRatingsTest['numRatingsByBook'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByBook'] < numRatingsCutoffHigh)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsCutoffHigh = 51\n",
    "numRatingsCutoffLow = 0\n",
    "pdFewRatings = pdRatingsTest[(pdRatingsTest['numRatingsByBook'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByBook'] < numRatingsCutoffHigh)]\n",
    "print ((pdRatingsTest['numRatingsByBook'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByBook'] < numRatingsCutoffHigh)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsCutoffHigh = 100000\n",
    "numRatingsCutoffLow = 70\n",
    "pdManyRatings = pdRatingsTest[(pdRatingsTest['numRatingsByUser'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByUser'] < numRatingsCutoffHigh)]\n",
    "print ((pdRatingsTest['numRatingsByUser'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByUser'] < numRatingsCutoffHigh)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsCutoffHigh = 71\n",
    "numRatingsCutoffLow = 0\n",
    "pdFewRatings = pdRatingsTest[(pdRatingsTest['numRatingsByUser'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByUser'] < numRatingsCutoffHigh)]\n",
    "print ((pdRatingsTest['numRatingsByUser'] > numRatingsCutoffLow) & (pdRatingsTest['numRatingsByUser'] < numRatingsCutoffHigh)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanWeights = np.linspace(0,1,20)\n",
    "\n",
    "rmsesSimple = []\n",
    "for weight in meanWeights:\n",
    "    rmsesSimple.append(mixedPred(glRatingsTestWithComm, \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                                            numTrainRatings_Test, \\\n",
    "                        False, False, True, weight)[1])\n",
    "\n",
    "\n",
    "rmsesSimpleManyRatings = []\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleManyRatings.append(mixedPred(gl.SFrame(pdManyRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                                            numTrainRatings_Test, \\\n",
    "                        False, False, True, weight)[1])\n",
    "    \n",
    "rmsesSimpleFewRatings = []\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleFewRatings.append(mixedPred(gl.SFrame(pdFewRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                                            numTrainRatings_Test, \\\n",
    "                        False, False, True, weight)[1])\n",
    "\n",
    "\n",
    "rmsesSocialRecManyRatings = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSocialRecManyRatings.append(\\\n",
    "                mixedPred(gl.SFrame(pdManyRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, True, False, weight)[1])\n",
    "    \n",
    "rmsesSocialRecFewRatings = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSocialRecFewRatings.append(\\\n",
    "                mixedPred(gl.SFrame(pdFewRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, True, False, weight)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(meanWeights, rmsesSimple,label='rmsesSimple')\n",
    "plt.plot(meanWeights, rmsesSimpleManyRatings,'-.',color='r',label='rmsesSimpleManyRatings')\n",
    "plt.plot(meanWeights, rmsesSimpleFewRatings,'-.',color='g',label='rmsesSimpleFewRatings')\n",
    "\n",
    "plt.plot(meanWeights, rmsesSocialRecManyRatings,'--',color='r',label='rmsesSocialRecManyRatings')\n",
    "plt.plot(meanWeights, rmsesSocialRecFewRatings,'--',color='g',label='rmsesSocialRecFewRatings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print min(rmsesSimple)\n",
    "print min(rmsesSimpleFewRatings)\n",
    "print min(rmsesSimpleManyRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsByComm = glRatingsTrainWithComm.groupby(['comm'], {'numRatings': gl.aggregate.COUNT('rating')})\n",
    "plt.hist(numRatingsByComm['numRatings']);\n",
    "np.sort(numRatingsByComm['numRatings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdRatingsTrain = glRatingsTrainWithComm.to_dataframe()\n",
    "pdRatingsTest = glRatingsTestWithComm.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRatingsByCommDict = defaultdict(int, {r['comm']: r['numRatings'] for r in numRatingsByComm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdRatingsTest['numRatingsByComm'] = pdRatingsTest['comm'].apply(lambda x: numRatingsByCommDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdRatingsTest['numRatingsByComm'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsCutoff = 1000\n",
    "pdManyRatings = pdRatingsTest[(pdRatingsTest['numRatingsByComm'] > numRatingsCutoff) & (pdRatingsTest['numRatingsByComm'] > 0)]\n",
    "print ((pdRatingsTest['numRatingsByComm'] > numRatingsCutoff) & (pdRatingsTest['numRatingsByComm'] > 0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRatingsCutoff = 1000\n",
    "pdFewRatings = pdRatingsTest[(pdRatingsTest['numRatingsByComm'] <= numRatingsCutoff) & (pdRatingsTest['numRatingsByComm'] > 0)]\n",
    "print ((pdRatingsTest['numRatingsByComm'] <= numRatingsCutoff) & (pdRatingsTest['numRatingsByComm'] > 0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanWeights = np.linspace(0,1,20)\n",
    "\n",
    "rmsesSimpleManyRatings = []\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleManyRatings.append(mixedPred(gl.SFrame(pdManyRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                                            numTrainRatings_Test, \\\n",
    "                        False, False, True, weight)[1])\n",
    "    \n",
    "rmsesSimpleFewRatings = []\n",
    "for weight in meanWeights:\n",
    "    rmsesSimpleFewRatings.append(mixedPred(gl.SFrame(pdFewRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine, \\\n",
    "                                            numTrainRatings_Test, \\\n",
    "                        False, False, True, weight)[1])\n",
    "\n",
    "\n",
    "rmsesSocialRecManyRatings = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSocialRecManyRatings.append(\\\n",
    "                mixedPred(gl.SFrame(pdManyRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, True, False, weight)[1])\n",
    "    \n",
    "rmsesSocialRecFewRatings = []\n",
    "\n",
    "for weight in meanWeights:\n",
    "    rmsesSocialRecFewRatings.append(\\\n",
    "                mixedPred(gl.SFrame(pdFewRatings[['userID','bookID','comm','rating']]), \\\n",
    "                          commMeansTrain, commBookMeansTrain, commBookMeansTrain, rec_engine, rec_engine_comm, \\\n",
    "                          numTrainRatings_Test, \\\n",
    "                          False, True, False, weight)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(meanWeights, rmsesSimple,label='rmsesSimple')\n",
    "plt.plot(meanWeights, rmsesSimpleManyRatings,'-.',color='r',label='rmsesSimpleManyRatings')\n",
    "plt.plot(meanWeights, rmsesSimpleFewRatings,'-.',color='g',label='rmsesSimpleFewRatings')\n",
    "\n",
    "plt.plot(meanWeights, rmsesSocialRecManyRatings,'--',color='r',label='rmsesSocialRecManyRatings')\n",
    "plt.plot(meanWeights, rmsesSocialRecFewRatings,'--',color='g',label='rmsesSocialRecFewRatings')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print meanWeights[np.argmin(rmsesSimple)]\n",
    "print meanWeights[np.argmin(rmsesSimpleManyRatings)]\n",
    "print meanWeights[np.argmin(rmsesSimpleFewRatings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdManyRatings['userID'].apply(lambda x: numRatingsByUserDict[x]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdFewRatings['userID'].apply(lambda x: numRatingsByUserDict[x]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
